<html>
<head>
    <link rel="stylesheet" href="/media/css/style.css">
    <title>Computational Psycholinguistics: Fall 2019</title>
</head>
<body>

<div class="inset">
    <h1>Computational Psycholinguistics: Fall 2019</h1>
    <p><b>Lecture:</b> Tuesdays and Thursdays, 1:30-2:45 pm</p>
    <p><b>Lab:</b> Fridays, 3:45-5:00 pm</p>
    <p><b>Krieger 134A</b></p>

    <table>
        <tr><td>Instructor</td><td> <p><a href="http://tallinzen.net">Tal Linzen</a></p><p>tal.linzen@jhu.edu</p><p>Office hour: Tuesday 3-4:30 pm, Krieger 243, <b>by appointment only</b> (see below)</p></td></tr>
        <tr><td style="padding-top: 20px">Teaching assistant</td><td style="padding-top: 20px"> <p><a href="https://tommccoy1.github.io/">Tom McCoy</a></p><p>tom.mccoy@jhu.edu</p><p>Office hour: Wed 4:30-5:30 pm, Krieger 141</p></tr>
    </table>

    <h2>Course description</h2>
	
    <p>
How do we understand and produce sentences in a language we speak? How do we acquire the knowledge that underlies this ability? Computational psycholinguistics seeks to address these questions using a combination of two approaches: computational models, which aim to replicate the processes that take place in the human mind; and human experiments, which are designed to test those models. The perspective we will take in this class is that models and experimental paradigms from psycholinguistics do not only advance our understanding of human cognitive science, but can also help us advance artificial intelligence and language technologies. While research in computational psycholinguistics spans all levels of linguistic structure, from speech to discourse, the focus of this class will be at the level of the sentence (syntax and semantics).
    </p>

<p>At the end of this class, you are expected to be able to:</p>

<ul>
    <li> Identify the central experimental tools and paradigms used in psycholinguistics.</li>
    <li> Explain central empirical findings concerning language comprehension and acquisition, in areas such as prediction, priming, and coping with syntactic ambiguity.</li>
    <li> Use computational tools such as grammars, Bayesian models and recurrent neural networks to implement basic computational psycholinguistic models.</li>
    <li> Design and run simple psycholinguistic experiments on humans and neural networks.
    <li> Design an original computational research project and report on it. Graduate students are expected to produce research that could be developed into a conference submission.</li>
</ul>

<p><b>Prerequisites:</b> I will assume you're familiar with probability theory (e.g., Bayes' law) and are comfortable with Python programming. I will also assume familiarity with basic concepts in linguistics. Experience with neural networks would be helpful but isn't essential.</p>

<h2>Course organization</h2>

<p><b>Lab:</b> The class will be accompanied by weekly lab sessions led by the Teaching Assistant. The goals of the lab are to reinforce the linguistic, mathematical and computational concepts covered in the lecture, and to provide hands-on technical introduction to the software tools that are essential for successful completion of the homework assignments and class project. <b>All students are expected to enroll in the lab</b>; exceptions will be granted by the professor on a case-by-case basis (for example, to students who can demonstrate existing research experience in computational linguistics / NLP).</p>

<p><b>Office hours:</b> If you'd like to attend my office hour, please sign up for a slot <a href="https://docs.google.com/spreadsheets/d/10lJ_Dmtq8cZ1LdND3r1aSALUAv3ESbUGnbiiVu4b8tw/edit?usp=sharing">on this spreadsheet</a>; do not show up without an appointment. To maximize access to office hours, the timing of the office hour may change from week to week (if there is sufficient demand). Please let me know if you're unable to attend my office hour due to a conflict and I'll schedule it at a different time the following week. My office hour is most appropriate for conceptual questions about course material and computational psycholinguistics more generally; technical issues and questions about the homework are best discussed in the lab section or the TA's office hour.</p>

<p><b>Interacting with the instructors:</b> If you have a question about the material, please ask it in class or in the lab, attend one of our office hours, or post the question on Piazza. We will only use email to communicate about personal or confidential matters.

<p><b>Anxiety, stress and mental health:</b> If you are struggling with anxiety, stress, depression or other mental health related concerns, please consider visiting the JHU Counseling Center. If you are concerned about a friend, please encourage that person to seek out their services. The Counseling Center is located at 3003 North Charles Street in Suite S-200 and can be reached at 410-516-8278 and <a href="http://studentaffairs.jhu.edu/counselingcenter">online</a>.</p>

<p><b>Disability services:</b> Any student with a disability who may need accommodations in this class should obtain an accommodation letter from Student Disability Services, studentdisabilityservices@jhu.edu, 385 Garland, (410) 516-4720. Please bring it to our attention as early as possible so we can do the best we can to accommodate your needs.

<h2>Course requirements</h2>

<p>Your responsibilities for the course are:</p>
<ul>
    <li>Attend the lectures <b>and participate regularly</b>.</li>
    <li>Attend the labs (except if you have received my permission not to attend them).</li>
    <li>If anything isn't clear, ask questions in class, on Piazza or during our office hours.</li>
    <li>Present a paper in class.</li>
    <li>Each week, make a comment or ask a question about one of the readings on Piazza.
    <li>Complete the homework assignments.</li>
    <li>Write a final project.</p>
</ul>

<p><b>Attendance:</b> Students are expected to attend all of the meetings of the class. We will occasionally check attendance. Please email the TA in advance if you need to miss a meeting for religious, health or any other <b>valid</b> reason. Do not come to class if you're sick; you do not need to bring a doctor's note, but again, do email the TA in advance to let us know you'll be missing class. Repeated unexplained absence will have consequences beyond the participation grade and may result in failure in the class.<p>

<p><b>Participation:</b> You are expected to engage in class discussion: ask questions, make comments and answer the instructors' questions. Make sure not to dominate the discussion, however: give all of the students space to participate.</p></p>

<p><b>Reactions to the readings:</b> As a component of the participation grade, each student will be expected to post one short question or comment on the readings to Piazza every week. The reactions to a reading are due before the class in which the reading is discussed. Your reactions are expected to demonstrate that you have read and thought about the article. You can skip up to three weeks without penalty; after that, every missed reaction will be penalized with a single point. Reactions (or comments on other students' reactions) that are particularly thoughtful or comments on other students' reactions, will be rewarded with an extra credit point, up to a maximum of 3 points.</p>

<p><b>Class presentation:</b> Each student&mdash;possibly in teams, depending on enrollment&mdash;will be expected to give a 45-minute presentation of one of the papers on the syllabus that present original research (that is, not a textbook chapter). While all students will have read the paper, the presentation should not assume that&mdash;it should be self-contained. Students are expected to present the theoretical motivation for the study, discuss relevant background (concisely), present the methodology and results of the study, and discuss its limitations. The time allotted to the presentation includes class discussion.</p>

<p><b>Homework assignments:</b> There will be six homework assignments. The assignments will have technical components, which will involve implementing computational models discussed in class, as well as short essay questions related to the readings. All homework assignments will be posted on Thursday after class and will be due the next Thursday before class.</p>

<p><b>Homework late days:</b> You have a budget of ten late days to be used at your discretion over the course of the semester, for any reason (e.g., illness); you do not need to ask for permission to use them. Use your late days wisely: once the budget has been exhausted, any late assignments will receive at most half of the possible points. Late days may only be used for homework assignments. They may not be used for reactions to the readings, for the final project, or for the intermediate deadlines for the final project.</p>


<p><b>Laptop policy:</b> Cognitive scientists have found that laptop use in the classroom can lead to lower test scores:</p>

<p>Raviza, S. M., Uitvlugt, M. G., &amp; Fenn, K. M. (2016). <a href="http://faculty.missouri.edu/segerti/1000/LaptopClassroomUse.pdf">Logged in and zoned out: How laptop Internet use relates to classroom learning.</a> Psychological Science, 28(2), 171&ndash;180.</p>

<p>See also the New York Times opinion piece, <a href="/media/readings/laptops_during_class.pdf">Laptops Are Great. But Not During a Lecture or a Meeting</a>.</p>

<p>We recommend that you avoid using your laptop in class, except for activities that are directly related to the class (e.g., following a Jupyter notebook in lab sessions).</p>

<p><b>Piazza:</b> We will be using a Piazza site to make announcements and answer questions. All enrolled students should have received an invitation to join the Piazza site. Alternatively, you can add yourself to the <a href="https://piazza.com/class/jztpxjvmydp1km">site</a>.

<p><b>Readings:</b> There is no required textbook. All of the readings will be available on this website. Many of the readings are from the <a href="https://web.stanford.edu/~jurafsky/slp3/">draft third edition</a> of Jurafsky and Martin's textbook <i>Speech and Language Processing</i>. Page numbers and chapters refer to the September 23, 2018 version. An optional resource to supplement the readings is Jacob Eisenstein's <a href="https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf">new NLP textbook</a> (also work in progress).</p>

<h2>Final project</h2>

<p>You will be expected to write a final paper reporting on an original research project in the area of computational psycholinguistics. The expected scope and ambition of the project will vary by section: graduate students are expected to write a report that could be submitted to a conference, while undergraduate projects can be more modest in scope. Teams of up to two students are allowed, though team projects are expected to be more ambitious. You will work with us throughout the semester to ensure that your project meets our expectations.</p>

The timeline for the project is as follows (all deadlines are by 6 pm Eastern time):</p>

<ul>
    <li>By September 27: Discuss a project idea with the TA.</li>
    <li>October 11: Email the instructor and the TA a project proposal. The subject of the email should be "CPL proposal:" followed by the full name(s) of the author(s). (20% of the project grade) </li>
    <li>October 24: Class presentation of project proposals, incorporating our comments on the proposal (approximately 10 minutes). (10%) </li>
    <li>December 1: Email the instructor and the TA a complete report on your project. The subject of the email should be "CPL project report:" followed by the full name(s) of the author(s). (50%) </li>
    <li>Class presentations in the final week of class. (10%) </li>
    <li>December 12: Revised report incorporating comments on the first report. (10%) </li>
</ul>

<p><b>Proposal:</b> The proposal should be up to two pages long (including references). It should include the following components:

<ul>
    <li>The research question. (30% of the proposal grade)</li>
    <li>Scientific and technological background, with references to prior work. (40%)</li>
    <li>Concrete steps you will undertake to complete the project, including a description of available resources that make the project feasible, such as corpora or human datasets. (30%) </li>
    <li>The expected division of labor between the team members, if relevant. (0%)</li> 
</ul>

<p><b>Final report:</b> The final report should be up to six pages including references. The report is expected to include the following content (not necessarily as distinct parts):

<ul>
    <li>Clear statement of the research question. (20% of the grade of the final report)</li>
    <li>Thorough but concise review of relevant prior work. (20%)</li>
    <li>Description of the methodology of the experiments. (15%)</li>
    <li>Results of the experiments. (15%)</li>
    <li>Discussion of how the results of the experiments bear on the original research question. (15%)</li>
    <li>Discussion of the the limitations of the study and directions for future work. (15%)</li>
</ul>

<p><b>Format:</b> Please use the <a href="https://raw.githubusercontent.com/rlevy/cogsci-template/master/cogsci_full_paper_template.tex">Cognitive Science Society (CogSci) LaTeX template</a> for both the proposal and the final report. Overleaf's <a href="https://www.overleaf.com/learn/latex/Learn_LaTeX_in_30_minutes">Learn LaTeX in 30 minutes</a> tutorial may be helpful to students who haven't used LaTeX before.</p>

<h2>Ethics policy</h2>

The strength of the university depends on academic and personal integrity. In this course, you must be honest and truthful. Ethical violations include cheating on exams, plagiarism, reuse of assignments, improper use of the Internet and electronic devices, unauthorized collaboration, alteration of graded assignments, forgery and falsification, lying, facilitating academic dishonesty, and unfair competition. Please report any ethics violations you witness to the instructor. You may consult the associate dean of student affairs and/or the chairman of the Ethics Board beforehand. See also the Guide on Academic Ethics for Undergraduates and the <a href="http://ethics.jhu.edu">Ethics Board Web site</a>. In particular:

<p><b>Do not cheat.</b> You are encouraged to talk with other students about the content of the course, and to use written material (lecture slides, the readings, external websites, newspaper/magazine stories, and so on) as sources, but your written work must be original to you, with the exception of short quotes that are clearly indicated as such (see next paragraph).</p>

<p><b>Do not plagiarize.</b> If you quote directly from a book or other resource, please indicate this with quotes ("...") and a parenthesized citation after the quoted material; in any case, do not quote extensively from other sources. If you are simply paraphrasing a portion of a resource, leave off the quotes but keep the citation. Use a simple format for citations, for example: "human language syntax is not regular (Chomsky 1957: pages xxx-xxx)".</p>

<h2>Course outline</h2>

<p>The topics and readings may change during the semester, depending on our rate of progress and interests.</p>

<h3>Probabilistic prediction</h3>

<ul>
    <li>Marta Kutas, Katherine DeLong &amp; Nathaniel Smith (2011). <a href="https://vorpus.org/papers/kutas-delong-smith-2011-chapter.pdf">A look around at what lies ahead: Prediction and predictability in language processing</a>. In <i>Predictions in the brain: Using our past to generate a future</i>.</li>
    <li>Nathaniel Smith &amp; Roger Levy (2013). <a href="https://vorpus.org/papers/smith-levy-2013-predictability-logarithmic.pdf">The effect of word predictability on reading time is logarithmic</a>. <i>Cognition</i>. <b>(Junghyun)</b></li>
    <li>SLP Chapter 3: <a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf">Language modeling with n-grams</a> (through 3.4, inclusive).</li>
    <li>(Probability refresher: Sharon Goldwater (2018), <a href="/media/readings/goldwater_basic_probability.pdf">Basic probability theory</a>.)
</ul>

<h3>Human parsing</h3>

<ul>
    <li>Lyn Frazier (1987). <a href="/media/readings/frazier_1987.pdf">Sentence processing: A tutorial review</a>. In <i>Attention and performance 12: The psychology of reading</i>, pages 560&ndash;569.</li>
    <li>Ken McRae &amp; Kazunaga Matsuki (2013). <a href="/media/readings/mcrae_matsuki_2013.pdf">Constraint-based models of sentence processing</a>. In <i>Sentence processing</i>, pages 51&ndash;62.</li>
    <li>Lyn Frazier &amp; Keith Rayner (1982). <a href="/media/readings/frazier_rayner_1982.pdf">Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences</a>. <i>Cognitive Psychology</i>.</li>
    <li>John Trueswell, Michael Tanenhaus and Susan Garnsey (1994). <a href="/media/readings/trueswell_tanenhaus_garnsey_1994.pdf">Semantic influences on parsing: Use of thematic role information in syntactic ambiguity resolution</a>. <i>Journal of Memory and Language</i>. <b>(Andrew)</b></li>
</ul>

<h3>Knowledge of grammar</h3>

<ul>
    <li>Noam Chomsky (1957). <a href="/media/readings/chomsky_syntactic_structures.pdf">Syntactic structures</a> (pages 13-25).</li>
    <li>SLP Chapter 10: <a href="https://web.stanford.edu/~jurafsky/slp3/10.pdf">Formal Grammars of English</a>.</li>
    <li>Jey Han Lau, Alexander Clark &amp; Shalom Lappin (2017). <a href="/media/readings/lau_clark_lappin_2017.pdf">Grammaticality, acceptability, and probability: a probabilistic view of linguistic knowledge</a>. <i>Cognitive Science</i>.</li>
</ul>


<h3>Computational parsers</h3>

<ul>
    <li>Jurafsky &amp; Martin, <i>Speech and Language Processing</i>, <b>Second Edition</b>, Chapter 13: Parsing with Context-Free Grammars (up to 13.4.2, inclusive).</li>
    <li>SLP Chapter 12: <a href="https://web.stanford.edu/~jurafsky/slp3/12.pdf">Statistical Parsers</a> (pages 1&ndash;14).</li>
    <li>Andreas Stolcke (1995). <a href="/media/readings/stolcke_1995.pdf">An efficient probabilistic context-free parsing algorithm that computes prefix probabilities</a>. <i>Computational Linguistics</i>. (pages 165&ndash;176)</li>
</ul>

<h3>Probabilistic models of human parsing</h3>

<ul>
    <li>Dan Jurafsky (1996). <a href="/media/readings/jurafsky_1996.pdf">A probabilistic model of lexical and syntactic access and disambiguation</a>. <i>Cognitive Science</i>. (sections 2.1-2.2 and 4.1-4.4). </li>
    <li>John Hale (2001). <a href="/media/readings/hale_2001.pdf">A probabilistic Earley parser as a psycholinguistic model</a>. <i>NAACL</i>.</li>
</ul>

<h3>Word vector representations</h3>

<ul>
    <li><a href="https://web.stanford.edu/~jurafsky/slp3/6.pdf">SLP Chapter 6</a>: Vector semantics (skip 6.5-6.7).</li>
    <li>Aylin Caliskan, Joanna Bryson &amp; Arvind Narayanan (2017). <a href="http://science.sciencemag.org/content/sci/356/6334/183.full.pdf">Semantics derived automatically from language corpora contain human-like biases</a>. <i>Science</i>.</li>
    <li>Tal Linzen, Emmanuel Dupoux &amp; Benjamin Spector (2016). <a href="https://www.aclweb.org/anthology/S16-2001">Quantificational features in distributional word representations</a>. <i>Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics</i>.</li>
    <li>(Background reading for students unfamiliar with neural networks: <a href="https://www.morganclaypool.com/doi/pdf/10.2200/S00762ED1V01Y201703HLT037">Goldberg (2017)</a>, pages 11&ndash;62.)
</ul>

<h3>Syntax in neural networks</h3>
<ul>
    <li>Yoav Goldberg (2017). <a href="https://www.morganclaypool.com/doi/pdf/10.2200/S00762ED1V01Y201703HLT037">Neural network methods for natural language processing</a>. Pages 163&ndash;189.</li>
    <li>Chris Olah (2015). <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs">Understanding LSTM networks</a>.</li>
    <li>Tal Linzen, Emmanuel Dupoux &amp; Yoav Goldberg (2016). <a href="/media/readings/linzen_dupoux_goldberg_2016_tacl.pdf">Assessing the ability of LSTMs to learn syntax-sensitive dependencies</a>. Transactions of the Association for Computational Linguistics. <b>(Chenyu)</b></li>
    <li>Ethan Wilcox, Roger Levy, Takashi Morita &amp; Richard Futrell (2018). <a href="/media/readings/wilcox_et_al_2018.pdf">What do RNN language models learn about filler-gap dependencies?</a>. BlackboxNLP 2018. <b>(Panayiota)</b></li>
    <li>Tom McCoy, Bob Frank &amp; Tal Linzen (2018). <a href="/media/readings/mccoy_et_al_2018.pdf">Revisiting the poverty of the stimulus: Hierarchical generalization without a hierarchical bias in recurrent neural networks</a>. Proceedings of the Annual Conference of the Cognitive Science Society.</li>
</ul>

<h3>Pragmatics as inference</h3>

<ul>
    <li>Noah Goodman &amp; Michael Frank (2016). <a href="/media/readings/goodman_frank_2016.pdf">Pragmatic language interpretation as probabilistic inference</a>. <i>Trends in Cognitive Sciences</i>.</li>
    <li>Leon Bergen, Roger Levy &amp; Noah Goodman (2016). <a href="/media/readings/bergen_levy_goodman_2016.pdf">Pragmatic reasoning through semantic inference.</a>, pages 6&ndash;14. <i>Semantics and Pragmatics.</i></li>
    <li>Justine Kao, Jean Wu, Leon Bergen &amp; Noah Goodman (2014). <a href="/media/readings/kao_et_al_2014.pdf">Nonliteral understanding of number words</a>. <i>PNAS</i>. <b>(Eric)</b></li>
</ul>

<h3>Information and communication</h3>
<ul>
    <li>Kyle Mahowald, Evelina Fedorenko, Steven Piantadosi &amp; Edward Gibson (2013). <a href="https://evlab.mit.edu/sites/default/files/documents/Mahowald_et_al_2013_Cognition.pdf">Info/information theory: Speakers choose shorter words in predictive contexts</a>. <i>Cognition</i>. <b>(Nathaniel)</b></li>
    <li>Florian Jaeger (2010). <a href="https://www.hlp.rochester.edu/resources/workshop_materials/EVELIN12/Jaeger10UIDcomplementizers-offprint.pdf">Redundancy and reduction: Speakers manage syntactic information density</a> (pages 23&ndash;27). <i>Cognitive Psychology</i>.</li>

<h3>"Good enough" processing and the noisy channel</h3>
    <li>SLP Appendix B: <a href="https://web.stanford.edu/~jurafsky/slp3/B.pdf">Spelling correction and the noisy channel (pages 1-7)</a>.</li>
    <li>Fernanda Ferreira (2003). <a href="/media/readings/ferreira_2003.pdf">The misinterpretation of noncanonical sentences</a>. Cognitive Psychology.</li>
    <li>Edward Gibson, Leon Bergen &amp; Steven Piantadosi (2013). <a href="https://www.pnas.org/content/pnas/110/20/8051.full.pdf">Rational integration of noisy evidence and prior semantic expectations in sentence interpretation</a>. PNAS.</li>
    <li>Roger Levy, Klinton Bicknell, Tim Slattery &amp; Keith Rayner (2009). <a href="https://www.pnas.org/content/pnas/106/50/21086.full.pdf">Eye movement evidence that readers maintain and act on uncertainty about past linguistic input</a>. PNAS.</li>
</ul>
</h3>

<h3>Syntactic priming and adaptation</h3>

<ul>
    <li>Kristen Tooley &amp; Matthew Traxler (2010). <a href="/media/readings/tooley_traxler_2010.pdf">Syntactic priming effects in comprehension: A critical review</a>. <i>Language and Linguistics Compass.</i></li>
    <li>Amit Dubey, Frank Keller &amp; Patrick Sturt (2006). <a href="/media/readings/dubey_et_al_2006.pdf">Integrating syntactic priming into an incremental probabilistic parser, with an application to psycholinguistic modeling.</a> <i>ACL</i>.</li>
    <li>Marten van Schijndel &amp; Tal Linzen (2018). <a href="http://tallinzen.net/media/papers/vanschijndel_linzen_2018_emnlp.pdf">A neural model of adaptation in reading</a>. <i>EMNLP</i>.</li>
</ul>

<h3>Memory and sentence processing</h3>
<ul>
    <li>Daniel Grodner &amp; Edward Gibson (2005). <a href="/media/readings/grodner_gibson_2005.pdf">Consequences of the serial nature of linguistic input for sentential complexity</a>. <i>Cognitive Science</i>.</li>
    <li>Rick Lewis &amp; Shravan Vasishth (2005). <a href="/media/readings/lewis_vasishth_2005.pdf">An activation-based model of sentence processing as skilled memory retrieval</a>. <i>Cognitive Science</i>.</li>
    <li>Roger Levy (2013). <a href="http://idiom.ucsd.edu/~rlevy/papers/levy-2013-memory-and-surprisal-corrected.pdf">Memory and surprisal in sentence processing</a>. Pages 78&ndash;87 and 99&ndash;103. In <i>Sentence Processing</i>.</li>
</ul>


<h2>Grading</h2>

<p><b>Extra credit:</b> There will be no individual extra credit opportunities.</p>

<p><b>Undergraduate grade composition:</b>
<ul><li>Homework assignments: 60%</li>
    <li>Project: 20%</li>
    <li>Class presentation: 10%</li>
    <li>Participation: 10%</p></ul>

<p><b>Graduate grade composition:</b>
<ul><li>Homework assignments: 42%</li>
    <li>Project: 38%</li>
    <li>Class presentation: 10%</li>
    <li>Participation: 10%</p></ul>


<p><b>Letter grades:</b> We will use the following key to assign letter grades:</p>

<table>
    <tr> <td>Number </td><td>Letter</td></tr>
<tr> <td> 97&ndash;100</td><td>A+</td></tr>
<tr> <td>   93&ndash;96</td><td>A</td></tr>
<tr> <td>   90&ndash;92</td><td>A-</td></tr>
<tr> <td>   87&ndash;89</td><td>B+</td></tr>
<tr> <td>   83&ndash;86</td><td>B</td></tr>
<tr> <td>   80&ndash;82</td><td>B-</td></tr>
<tr> <td>   77&ndash;79</td><td>C+</td></tr>
<tr> <td>   73&ndash;76</td><td>C</td></tr>
<tr> <td>   70&ndash;72</td><td>C-</td></tr>
<tr> <td>   60&ndash;69</td><td>D</td></tr>
<tr> <td>   0&ndash;59</td><td>F</td></tr>
</table>

    <table>
        <tr></tr>
    </table>
</div>
</body>
</html>
